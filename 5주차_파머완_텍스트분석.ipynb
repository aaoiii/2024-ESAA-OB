{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj9JhAYQbv2u21k9B8lMMn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaoiii/2024-ESAA-OB/blob/main/5%EC%A3%BC%EC%B0%A8_%ED%8C%8C%EB%A8%B8%EC%99%84_%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 06 토픽 모델링 (Topic Modeling) - 20 뉴스그룹\n",
        "\n",
        "토픽 모델링 : 문서 집합에 숨어있는 주제를 찾아내는 것\n",
        "- LSA (Latent Semantic Analysis), LDA (Latent Dirichlet Allocation) -> 차원축소의 LDA와 다른 알고리즘!\n",
        "\n"
      ],
      "metadata": {
        "id": "8nHG70pP0rqy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJiCs7NzzViZ",
        "outputId": "50a4ab9e-4157-40a1-af15-58dc23d8df70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer Shape: (7862, 1000)\n"
          ]
        }
      ],
      "source": [
        "# fetch_20newsgroups() : categories파라미터를 통해 필요한 주제만 필터링해 추출하고\n",
        "#추출된 텍스트를 Count 기반으로 벡터화 변환\n",
        "# LDA 는 Count 기반의 벡터화만 사용\n",
        "# max_features=1000 으로 word 피처의 개수 제한\n",
        "# ngram_range를 (1,2)로 설정하고 피처 벡터화 변환\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "#모토사이클, 야구, 그래픽스. 윈도우즈, 중동, 기독교, 전자공학, 의학 8개 주제를 추출\n",
        "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
        "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med']\n",
        "\n",
        "#위에서 cats 변수로 기재된 카테고리만 추출. featch_20newgroups()의 categories에 cats 입력\n",
        "news_df = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'),\n",
        "                             categories=cats, random_state=0)\n",
        "\n",
        "#LDA는 Count기반의 벡터화만 적용합니다.\n",
        "count_vect = CountVectorizer(max_df=0.95, max_features = 1000, min_df = 2, stop_words='english',\n",
        "                             ngram_range=(1,2))\n",
        "\n",
        "feat_vect = count_vect.fit_transform(news_df.data)\n",
        "print('CountVectorizer Shape:', feat_vect.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토픽의 개수 : 뉴스그룹에서 추출한 주제와 동일한 8개로 정한다\n",
        "# n_components 로 토픽 개수 조정\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=8,random_state=0)\n",
        "lda.fit(feat_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "PCg7umcb2N63",
        "outputId": "4b53cf2b-f826-458e-95ba-25f9a86fe5a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=8, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=8, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=8, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# components_ : 개별 토픽별로 각 word 피처가 얼마나 많이 그 토픽에 할당됐는지에 대한 수치\n",
        "# 높을수록 해당 word 피처는 그 토픽의 중심 word 가 된다\n",
        "\n",
        "print(lda.components_.shape)\n",
        "lda.components_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faxE78tr2N4u",
        "outputId": "67641184-6b98-4862-b824-351b6da5cca3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 1000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
              "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
              "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
              "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
              "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
              "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
              "       ...,\n",
              "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
              "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
              "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
              "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
              "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
              "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display_topics() 함수를 만들어서 각 토픽별로 연관도가 높은 순으로 Word 나열\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "  for topic_index, topic in enumerate(model.components_):\n",
        "    print('Topic #', topic_index)\n",
        "\n",
        "    #components_array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array 인덱스를 반환.\n",
        "    topic_word_indexed = topic.argsort()[::-1]\n",
        "    top_indexes = topic_word_indexed[:no_top_words]\n",
        "\n",
        "    #top_indexes 대상인 인덱스별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
        "    feature_concat = ''.join([feature_names[i] for i in top_indexes])\n",
        "    print(feature_concat)\n",
        "\n",
        "#CountVectorizer객체 내의 전체 word의 명칭을 get_features_names()를 통해 추출\n",
        "feature_names = count_vect.get_feature_names_out()\n",
        "\n",
        "#토픽별 가장 연관도가 높은 word를 15개만 추출\n",
        "display_topics(lda, feature_names, 15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKG3jknT2N2m",
        "outputId": "f8d50452-147f-497a-8656-6b8f0df68c15"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic # 0\n",
            "year10gamemedicalhealthteam1220diseasecancer1993gamesyearspatientsgood\n",
            "Topic # 1\n",
            "donjustlikeknowpeoplesaidthinktimevedidnrightgoingsayllway\n",
            "Topic # 2\n",
            "imagefilejpegprogramgifimagesoutputformatfilescolorentry00usebit03\n",
            "Topic # 3\n",
            "likeknowdonthinkusedoesjustgoodtimebookreadinformationpeopleusedpost\n",
            "Topic # 4\n",
            "armenianisraelarmeniansjewsturkishpeopleisraelijewishgovernmentwardos dosturkeyarabarmenia000\n",
            "Topic # 5\n",
            "educomavailablegraphicsftpdatapubmotifmailwidgetsoftwaremitinformationversionsun\n",
            "Topic # 6\n",
            "godpeoplejesuschurchbelievechristdoeschristiansaythinkchristiansbiblefaithsinlife\n",
            "Topic # 7\n",
            "usedosthankswindowsusingwindowdoesdisplayhelplikeproblemserverneedknowrun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Topic #0 : 명확하지 않고 일반적인 단어가 주\n",
        "- Topic #1 : 명확하게 컴퓨터 그래픽스 영역의 주제어 추출\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "b92uXbEN7-4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 08 문서 유사도\n",
        "\n",
        "## 코사인 유사도\n",
        "- 벡터와 벡터간의 유사도를 비교할 때 벡터의 크기보다는 벡터의 상호 방향성이 얼마나 유사한지에 기반\n",
        "- 두 벡터 사이의 사잇각을 구해서 얼마나 유사한지 수치로 적용\n",
        "- cos_similarity() 함수"
      ],
      "metadata": {
        "id": "WwywbPwp8sxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cos_similarity(v1, v2):\n",
        "  dot_product = np.dot(v1, v2)\n",
        "  l2_norm = (np.sqrt(sum(np.square(v1))) * np.sqrt(sum(np.square(v2))))\n",
        "  similarity = dot_product / l2_norm\n",
        "\n",
        "  return similarity"
      ],
      "metadata": {
        "id": "sUClu_BG2N0N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# doc_list로 정의된 3개의 간단한 문서의 유사도를 비교하기 위해 이 문서를 TF-IDF로 벡터화된 행렬로 변환\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "doc_list = [\n",
        "    'if you take the blue pill, the story ends',\n",
        "    'if you take the red pill, you stay in Wonderland',\n",
        "    'if you take the red pill, I show you how deep the rabbit hole goes'\n",
        "]\n",
        "\n",
        "tfidf_vect_simple = TfidfVectorizer()\n",
        "feature_vect_simple = tfidf_vect_simple.fit_transform(doc_list)\n",
        "print(feature_vect_simple.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP2I4K7e2Nvs",
        "outputId": "22cefd11-9429-47ab-9383-fa80b596d1d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 반환된 행렬을 희소행렬이므로 앞에서 작성한 cos_similarity() 함수의 인자인 array로 만들기 위해 밀집 행렬로 변환후 다시 각각을 배열로 변환"
      ],
      "metadata": {
        "id": "FEWcEGVjB6uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer로 transform()한 결과는 희소 행렬이므로 밀집 행렬로 변환.\n",
        "feature_vect_dense = feature_vect_simple.todense()\n",
        "\n",
        "#첫 번째 문장과 두 번째 문장의 피처 벡터 추출\n",
        "vect1 = np.array(feature_vect_dense[0]).reshape(-1, )\n",
        "vect2 = np.array(feature_vect_dense[1]).reshape(-1, )\n",
        "\n",
        "#첫 번째 문장과 두 번째 문장의 피처 벡터로 두 개 문장의 코사인 유사도 추출\n",
        "similarity_simple = cos_similarity(vect1, vect2)\n",
        "print('문장 1, 문장 2 Cosine 유사도 : {0:3f}'.format(similarity_simple))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2bZDCPeC7hr",
        "outputId": "491b7af2-be5f-42fa-9cbd-4311772c65fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 1, 문장 2 Cosine 유사도 : 0.402078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 번째 문장과 세 번째 문장의 유사도 측정\n",
        "vect1 = np.array(feature_vect_dense[0]).reshape(-1, )\n",
        "vect3 = np.array(feature_vect_dense[2]).reshape(-1, )\n",
        "similarity_simple = cos_similarity(vect1, vect3)\n",
        "print('문장 1, 문장 3 Cosine 유사도 : {0:3f}'.format(similarity_simple))\n",
        "\n",
        "vect2 = np.array(feature_vect_dense[1]).reshape(-1, )\n",
        "vect3 = np.array(feature_vect_dense[2]).reshape(-1, )\n",
        "similarity_simple = cos_similarity(vect2, vect3)\n",
        "print('문장 2, 문장 3 Cosine 유사도 : {0:3f}'.format(similarity_simple))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_WLzqlaC8KE",
        "outputId": "ab3d7a9a-a323-4898-ba71-5d7cdccb97e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 1, 문장 3 Cosine 유사도 : 0.404250\n",
            "문장 2, 문장 3 Cosine 유사도 : 0.456473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- cosine_similarity()는 두개의 입력 파라미터를 받는다\n",
        "  - 비교 기준이 되는 문서의 피처 행렬, 비교되는 문서의 피처 행렬"
      ],
      "metadata": {
        "id": "7ksW0qgyDV-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_simple_pair = cosine_similarity(feature_vect_simple[0], feature_vect_simple)\n",
        "print(similarity_simple_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjqL7AhkC8H_",
        "outputId": "46c4ed29-a307-4d95-f4df-58125f37384a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.40207758 0.40425045]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1은 첫 번째 문서 자신에 대한 유사도 측정\n",
        "- 두 번째 유사도 값은 첫 번째와 두 번째 문서의 유사도\n",
        "- 세 번째 유사도 값은 첫 번째와 세 번째 문서의 유사도"
      ],
      "metadata": {
        "id": "1OypWhMsDyQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_simple_pair = cosine_similarity(feature_vect_simple[0], feature_vect_simple[1:])\n",
        "print(similarity_simple_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxdsJsBtC8Fm",
        "outputId": "4562a8d3-d8fd-40cf-ce47-d02a5c0308dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.40207758 0.40425045]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_simple_pair = cosine_similarity(feature_vect_simple, feature_vect_simple)\n",
        "print(similarity_simple_pair)\n",
        "print('shape:', similarity_simple_pair.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwpWMAY2C8De",
        "outputId": "06749413-5f62-4da7-ce91-0060c787f89f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.40207758 0.40425045]\n",
            " [0.40207758 1.         0.45647296]\n",
            " [0.40425045 0.45647296 1.        ]]\n",
            "shape: (3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Opinion Review 데이터 세트를 이용한 문서 유사도 측정"
      ],
      "metadata": {
        "id": "EN0M7EsEFAUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 새롭게 DataFrame으로 로드하고 문서 군집화 적용\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "lemmar = WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "  return [lemmar.lemmatize(token) for token in tokens]\n",
        "\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5SNwJFKC8BK",
        "outputId": "1b97b064-c7d8-4d43-8b10-c7a52daed655"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob, os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "path = r'C:\\Users\\candi\\Documents\\OpinosisDataset1.0\\topics'\n",
        "all_files = glob.glob(os.path.join(path, '*.data'))\n",
        "filename_list = []\n",
        "opinion_text = []\n",
        "\n",
        "for file_ in all_files:\n",
        "  df = pd.read_table(file_, index_col=None, header=0, encoding='latin1')\n",
        "  filename_ = file_.split('\\')[-1]\n",
        "  filename = filename_.split('.')[0]\n",
        "  filename_list.append(filename)\n",
        "  opinion_text.append(df.to_string())\n",
        "\n",
        "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english',\n",
        "                             ngram_range=(1,2), min_df=0.05, max_df=0.85)\n",
        "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])"
      ],
      "metadata": {
        "id": "qaJo5G_pUbQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
        "km_cluster.fit(feature_vect)\n",
        "cluster_label = km_cluster.labels_\n",
        "cluster_centers = km_cluster.cluster_centers_\n",
        "document_df['cluster_label'] = cluster_label"
      ],
      "metadata": {
        "id": "VSpBzbXiU0_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# cluster_label=1인 데이터는 호텔로 군집화된 데이터임. DataFrame에서 해당 인덱스를 추출\n",
        "hotel_indexes = document_df[document_df['cluster_label']==1].index\n",
        "print('호텔로 군집화된 문서들의 DataFrame Index:', hotel_indexes)\n",
        "\n",
        "# 호텔로 군집화된 데이터 중 첫 번째 문서를 추출해 파일명 표시\n",
        "comparison_docname = document_df.iloc[hotel_indexes[0]]['filename']\n",
        "print('##### 비교 기준 문서명 ', comparison_docname, ' 와 타 문서 유사도#####')\n",
        "\n",
        "''' document_df에서 추출한 Index 객체를 feature_vect로 입력해 호텔 군집화된 feature_vect 추출\n",
        "이를 이용해 호텔로 군집화된 문서 중 첫 번째 문서와 다른 문서 간의 코사인 유사도 측정 '''\n",
        "similarity_pair = cosine_similarity(feature_vect[hotel_indexes[0]], feature_vect[hotel_indexes])\n",
        "print(similarity_pair)"
      ],
      "metadata": {
        "id": "WN15NV0qU8TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 유사도가 높은 순으로 정렬하고 시각화하기\n",
        " - cosine_similarity() 는 쌍 형태의 ndarray를 반환하므로 이를 판다스 인덱스로 이용하기 위해 reshape(-1)로 차원 변경"
      ],
      "metadata": {
        "id": "V_FEzzPrVHA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 첫 번째 문서와 타 문서 간 유사도가 큰 순으로 정렬한 인덱스를 추출하되 자기 자신은 제외\n",
        "sorted_index = similarity_pair.argsort()[:, ::-1]\n",
        "sorted_index = sorted_index[:, 1:]\n",
        "\n",
        "# 유사도가 큰 순으로 hotel_indexes를 추출해 재정렬\n",
        "hotel_sorted_indexes = hotel_indexes[sorted_index.reshape(-1)]\n",
        "\n",
        "# 유사도가 큰 순으로 유사도 값을 재정렬하되 자기 자신은 제외\n",
        "hotel_1_sim_value = np.sort(similarity_pair.reshape(-1))[::-1]\n",
        "hotel_1_sim_value = hotel_1_sim_value[1:]\n",
        "\n",
        "# 유사도가 큰 순으로 정렬된 인덱스와 유사도 값을 이용해 파일명과 유사도 값을 막대 그래프로 시각화\n",
        "hotel_1_sim_df = pd.DataFrame()\n",
        "hotel_1_sim_df['filename'] = document_df.iloc[hotel_sorted_indexes]['filename']\n",
        "hotel_1_sim_df['similarity'] = hotel_1_sim_value\n",
        "\n",
        "sns.barplot(x='similarity', y='filename', data=hotel_1_sim_df)\n",
        "plt.title(comparison_docname)"
      ],
      "metadata": {
        "id": "rKi9qnpKVQrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 09 한글 텍스트 처리 - 네이버 영화 평점 감성 분석\n",
        "\n",
        "한글의 띄어쓰기와 조사를 주의해야한다\n",
        "\n",
        "**KoNLPy**\n",
        "- 파이썬의 대표적인 한글 형태소 패키지\n",
        "- 형태소 분석 : 말뭉치를 형태소 어근 단위로 쪼개고 각 형태소에 품사 태깅을 부착하는 작업"
      ],
      "metadata": {
        "id": "Pf5WcUNTVUew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fCnuMJlVTJl",
        "outputId": "c691cf18-d712-4908-9a8c-6f1145de6016"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('ratings_train.txt', sep='\\t')\n",
        "train_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "rgUA8e2kWIuu",
        "outputId": "4f340416-6cf8-4855-dc31-1f47901b2dea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                           document  label\n",
              "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fde5cb3-70ba-47c4-827d-b991c838801b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fde5cb3-70ba-47c4-827d-b991c838801b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fde5cb3-70ba-47c4-827d-b991c838801b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fde5cb3-70ba-47c4-827d-b991c838801b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80b53884-0f2f-478e-9488-6a5162e70cff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80b53884-0f2f-478e-9488-6a5162e70cff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80b53884-0f2f-478e-9488-6a5162e70cff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo0k1oqnWQop",
        "outputId": "0304c141-54c5-4997-cc80-1fd77491111f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    75173\n",
              "1    74827\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 0과 1의 비율이 균등한 분포\n",
        "- document 칼럼에 Null이 일부 존재하므로 이 값을 공백으로 변환\n",
        "- re를 이용해 문자가 아닌 숫자의 경우도 공백으로 변환"
      ],
      "metadata": {
        "id": "e7CloZm_WUOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "train_df = train_df.fillna(' ')\n",
        "# 정규 표현식을 이용해 숫자를 공백으로 변경(정규 표현식으로 \\d는 숫자를 의미함)\n",
        "train_df['document'] = train_df['document'].apply(lambda x : re.sub(r'\\d+', ' ', x))\n",
        "\n",
        "# 테스트 데이터 세트를 로딩하고 동일하게 Null 및 숫자를 공백으로 변환\n",
        "test_df = pd.read_csv('ratings_test.txt', sep='\\t')\n",
        "test_df = test_df.fillna(' ')\n",
        "test_df['document'] = test_df['document'].apply(lambda x : re.sub(r'\\d+', ' ', x))\n",
        "\n",
        "# id 칼럼 삭제 수행\n",
        "train_df.drop('id', axis=1, inplace=True)\n",
        "test_df.drop('id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Ms4giuNZWIrL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "한글 형태소 분석을 통해 형태소 단어로 토큰화\n",
        "- 한글 형태소 엔진은 SNS 분석에 적합한 Twitter 클래스 이용\n",
        "- Twitter 객체의 morphs() 메서드 이용"
      ],
      "metadata": {
        "id": "5oMjwZOlWoFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Twitter\n",
        "\n",
        "twitter = Twitter()\n",
        "def tw_tokenizer(text):\n",
        "  # 입력 인자로 들어온 텍스트를 형태소 단어로 토큰화해 리스트 형태로 반환\n",
        "  tokens_ko = twitter.morphs(text)\n",
        "  return tokens_ko"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ELN_HI2WyEH",
        "outputId": "faba14be-37d3-4718-a370-98919dd91b7d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TfidVectorizer을 이용해 TF-IDF 피처 모델 생성"
      ],
      "metadata": {
        "id": "D3o2qCgzW1x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Twitter 객체의 morphs() 객체를 이용한 tokenizer를 사용, ngram_range는 (1,2)\n",
        "tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
        "tfidf_vect.fit(train_df['document'])\n",
        "tfidf_matrix_train = tfidf_vect.transform(train_df['document'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMdwUrDYW6le",
        "outputId": "b8fabb3b-f28f-4a5f-f4ce-c7339c80305d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀를 이용해 분류 기반의 감성분석 수행"
      ],
      "metadata": {
        "id": "4sWvoGoMW9mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 로지스틱 회귀를 이용해 감정 분석 분류 수행\n",
        "lg_clf = LogisticRegression(random_state=0)\n",
        "\n",
        "# 파라미터 C 최적화를 위해 GridSearchCV를 이용\n",
        "params = {'C': [1,3.5,4.5,5.5,10]}\n",
        "\n",
        "grid_cv = GridSearchCV(lg_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_cv.fit(tfidf_matrix_train, train_df['label'])\n",
        "print(grid_cv.best_params_, round(grid_cv.best_score_, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCl2bLUiXEOi",
        "outputId": "f53b0862-17bd-46d9-ff3c-95b759ecce70"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 3.5} 0.8593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 세트를 이용해 최종 감성 분석 예측 수행\n",
        "- 학습할 때 적용한 TfidVectorizer을 그대로 사용해야한다"
      ],
      "metadata": {
        "id": "OBDWoD7GXH4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 학습 데이터를 적용한 TfidfVectorizer를 이용해 테스트 데이터를 TF-IDF 값으로 피처 변환함\n",
        "tfidf_matrix_test = tfidf_vect.transform(test_df['document'])\n",
        "\n",
        "# classifier는 GridSearchCV에서 최적 파라미터로 학습된 classifier를 그대로 이용\n",
        "best_estimator = grid_cv.best_estimator_\n",
        "preds = best_estimator.predict(tfidf_matrix_test)\n",
        "\n",
        "print('Logistic Regression 정확도: ', accuracy_score(test_df['label'], preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2eVOuhPXGDe",
        "outputId": "a48c67c2-863d-45e7-d8c9-ac135957e4d5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression 정확도:  0.86186\n"
          ]
        }
      ]
    }
  ]
}