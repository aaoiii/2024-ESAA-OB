{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaoiii/2024-ESAA-OB/blob/main/4_5_%EC%84%B8%EC%85%98_%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%B6%84%EC%84%9D_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 아래의 데이터를 이용하여 공부한 내용을 바탕으로 문제 2개를 만들고 답하세요."
      ],
      "metadata": {
        "id": "MbDTRcUQrUS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"book\", quiet=True)\n",
        "from nltk.book import *"
      ],
      "metadata": {
        "id": "PNjdc83Bqdpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08241c7b-e072-409f-ecd3-f6d5965c4d18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 목록 확인\n",
        "nltk.corpus.gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9xoXfKzrbKv",
        "outputId": "3305707d-a8f2-4abf-f566-325a6101aeaf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emma = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "print(emma[:5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo9kzrrqqaNc",
        "outputId": "9ecb0e32-cb16-472e-e796-9cadce881967"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Emma by Jane Austen 1816]\n",
            "\n",
            "VOLUME I\n",
            "\n",
            "CHAPTER I\n",
            "\n",
            "\n",
            "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
            "and happy disposition, seemed to unite some of the best blessings\n",
            "of existence; and had lived nearly twenty-one years in the world\n",
            "with very little to distress or vex her.\n",
            "\n",
            "She was the youngest of the two daughters of a most affectionate,\n",
            "indulgent father; and had, in consequence of her sister's marriage,\n",
            "been mistress of his house from a very early period.  Her mother\n",
            "had died too long ago for her to have more than an indistinct\n",
            "remembrance of her caresses; and her place had been supplied\n",
            "by an excellent woman as governess, who had fallen little short\n",
            "of a mother in affection.\n",
            "\n",
            "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
            "less as a governess than a friend, very fond of both daughters,\n",
            "but particularly of Emma.  Between _them_ it was more the intimacy\n",
            "of sisters.  Even before Miss Taylor had ceased to hold the nominal\n",
            "office of governess, the mildness of her temper had hardly allowed\n",
            "her to impose any restraint; and the shadow of authority being\n",
            "now long passed away, they had been living together as friend and\n",
            "friend very mutually attached, and Emma doing just what she liked;\n",
            "highly esteeming Miss Taylor's judgment, but directed chiefly by\n",
            "her own.\n",
            "\n",
            "The real evils, indeed, of Emma's situation were the power of having\n",
            "rather too much her own way, and a disposition to think a little\n",
            "too well of herself; these were the disadvantages which threatened\n",
            "alloy to her many enjoyments.  The danger, however, was at present\n",
            "so unperceived, that they did not by any means rank as misfortunes\n",
            "with her.\n",
            "\n",
            "Sorrow came--a gentle sorrow--but not at all in the shape of any\n",
            "disagreeable consciousness.--Miss Taylor married.  It was Miss\n",
            "Taylor's loss which first brought grief.  It was on the wedding-day\n",
            "of this beloved friend that Emma first sat in mournful thought\n",
            "of any continuance.  The wedding over, and the bride-people gone,\n",
            "her father and herself were left to dine together, with no prospect\n",
            "of a third to cheer a long evening.  Her father composed himself\n",
            "to sleep after dinner, as usual, and she had then only to sit\n",
            "and think of what she had lost.\n",
            "\n",
            "The event had every promise of happiness for her friend.  Mr. Weston\n",
            "was a man of unexceptionable character, easy fortune, suitable age,\n",
            "and pleasant manners; and there was some satisfaction in considering\n",
            "with what self-denying, generous friendship she had always wished\n",
            "and promoted the match; but it was a black morning's work for her.\n",
            "The want of Miss Taylor would be felt every hour of every day.\n",
            "She recalled her past kindness--the kindness, the affection of sixteen\n",
            "years--how she had taught and how she had played with her from five\n",
            "years old--how she had devoted all her powers to attach and amuse\n",
            "her in health--and how nursed her through the various illnesses\n",
            "of childhood.  A large debt of gratitude was owing here; but the\n",
            "intercourse of the last seven years, the equal footing and perfect\n",
            "unreserve which had soon followed Isabella's marriage, on their\n",
            "being left to each other, was yet a dearer, tenderer recollection.\n",
            "She had been a friend and companion such as few possessed: intelligent,\n",
            "well-informed, useful, gentle, knowing all the ways of the family,\n",
            "interested in all its concerns, and peculiarly interested in herself,\n",
            "in every pleasure, every scheme of hers--one to whom she could speak\n",
            "every thought as it arose, and who had such an affection for her\n",
            "as could never find fault.\n",
            "\n",
            "How was she to bear the change?--It was true that her friend was\n",
            "going only half a mile from them; but Emma was aware that great must\n",
            "be the difference between a Mrs. Weston, only half a mile from them,\n",
            "and a Miss Taylor in the house; and with all her advantages,\n",
            "natural and domestic, she was now in great danger of suffering\n",
            "from intellectual solitude.  She dearly loved her father, but he\n",
            "was no companion for her.  He could not meet her in conversation,\n",
            "rational or playful.\n",
            "\n",
            "The evil of the actual disparity in their ages (and Mr. Woodhouse had\n",
            "not married early) was much increased by his constitution and habits;\n",
            "for having been a valetudinarian all his life, without activity\n",
            "of mind or body, he was a much older man in ways than in years;\n",
            "and though everywhere beloved for the friendliness of his heart\n",
            "and his amiable temper, his talents could not have recommended him\n",
            "at any time.\n",
            "\n",
            "Her sister, though comparatively but little removed by matrimony,\n",
            "being settled in London, only sixteen miles off, was much beyond\n",
            "her daily reach; and many a long October and November evening must\n",
            "be struggled through at Hartfield, before Christmas brought the next\n",
            "visit from Isabella and her husband, and their little children,\n",
            "to fill the house, and give her pleasant society again.\n",
            "\n",
            "Highbury, the large and populous village, almost amounting to a town,\n",
            "to which Hartfield, in spite of its separate lawn, and shrubberies,\n",
            "and name, did really belong, afforded her no equals.  The Woodhouses\n",
            "were \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 문제 1 : 첫번째 문장의 단어를 토큰화하고 스톱워드를 제거하여 분석에 필요한 단어만 남겨보세요"
      ],
      "metadata": {
        "id": "iNftR22-riz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = emma[50:285]"
      ],
      "metadata": {
        "id": "kIVaipvQoOnR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gjR-NnITsM_J",
        "outputId": "47402b8f-7c25-4743-9d94-6b5b35cf5a6d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Emma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "words = word_tokenize(sentence)\n",
        "print(type(words), len(words))\n",
        "print(words)\n",
        ""
      ],
      "metadata": {
        "id": "rqidjKSFrl-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4929061f-9907-4a6c-afdf-b58ac8e28eaa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 45\n",
            "['Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "all_tokens = []\n",
        "filtered_words = []\n",
        "\n",
        "if words not in stopwords :\n",
        "  filtered_words.append(words)\n",
        "  all_tokens.append(filtered_words)\n",
        "\n",
        "print(all_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHJ4X97Konpg",
        "outputId": "c9786177-39ca-4972-8d40-26c8c0a97b12"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 문제 2 : 문서에 대해 카운트기반 벡터화를 해보세요"
      ],
      "metadata": {
        "id": "F6fES2kkrmP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#리스트 형태로 변환\n",
        "emma = [emma]"
      ],
      "metadata": {
        "id": "DtB67AGSqPQ0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(emma)\n"
      ],
      "metadata": {
        "id": "lMVBVYAOr3dY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# CountVectorizer 객체 생성\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# 텍스트 데이터를 특성 벡터로 변환\n",
        "X = vectorizer.fit_transform(words)"
      ],
      "metadata": {
        "id": "a9vmAhP1rnIi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"특성 이름 (단어):\")\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"\\n변환된 특성 벡터:\")\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0cH7ZUQqU_W",
        "outputId": "636badae-c533-4980-95cc-d84c594ffb9e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "특성 이름 (단어):\n",
            "['000' '10' '1816' ... 'youthful' 'zeal' 'zigzags']\n",
            "\n",
            "변환된 특성 벡터:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 조원들과 만든 문제와 답을 공유해보세요."
      ],
      "metadata": {
        "id": "2EvgMg6VsMz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 1 : hamlet에서 1000번째 문장 찾기\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "hamlet = nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')\n",
        "sentences = sent_tokenize(hamlet)\n",
        "sentence = sent_tokenize(hamlet)[999]\n",
        "print(sentence)\n",
        "\n",
        "# 문제 2 : hamlet의 1000번째 문장에서 5번째 단어 찾기\n",
        "from nltk import word_tokenize\n",
        "words = word_tokenize(sentence)\n",
        "word = words[4]\n",
        "print(word)"
      ],
      "metadata": {
        "id": "a_l-4BAwsPlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5b1150-9255-437d-e961-7f841c629519"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This was sometime a Paradox, but now the time giues it\n",
            "proofe.\n",
            "Paradox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 3 : emma[:5000]에서 스톱 워드 제거하기\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk import word_tokenize\n",
        "emma5000 = emma[:5000]\n",
        "# 단어 토큰화\n",
        "emma_words = word_tokenize(emma5000)\n",
        "print(len(emma_words))\n",
        "print(emma_words)\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "filtered_words = []\n",
        "for word in emma_words:\n",
        "  word = word.lower()\n",
        "  if word not in stopwords:\n",
        "    filtered_words.append(word)\n",
        "print(filtered_words)\n",
        "\n",
        "# 문제 4 : 스톱 워드 제거하고 남은 단어들의 원형 찾기\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "stemmed_tokens = [lemma.lemmatize(token) for token in filtered_words]\n",
        "stemmed_tokens"
      ],
      "metadata": {
        "id": "1bg9TtbQwrOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 5 : nltk 패키지를 이용하지 않고 텍스트를 단어로 토큰화 하시오.\n",
        "\n",
        "# 텍스트를 단어로 토큰화\n",
        "tokens = emma.split()\n",
        "\n",
        "# 토큰 출력\n",
        "print(tokens)\n",
        "\n",
        "import re\n",
        "\n",
        "# 텍스트를 문장부호와 함께 단어로 토큰화\n",
        "tokens = re.findall(r'\\b\\w+\\b|[.,;?!]', emma)\n",
        "\n",
        "# 토큰 출력\n",
        "print(tokens)\n",
        "\n",
        "\n",
        "def word_tokenize(text):\n",
        "    # 공백을 기준으로 단어 토큰화\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# 단어 토큰화 함수 호출\n",
        "tokens = word_tokenize(emma)\n",
        "\n",
        "# 토큰 출력\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "WvelKbAmwxNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 6 : 희소 행렬 만들기\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# CountVectorizer를 사용하여 텍스트를 희소행렬로 변환\n",
        "vectorizer = CountVectorizer()\n",
        "sparse_matrix = vectorizer.fit_transform([emma])\n",
        "\n",
        "# 희소행렬 출력\n",
        "print(\"희소행렬:\\n\", sparse_matrix)\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# CountVectorizer를 사용하여 텍스트를 희소행렬로 변환\n",
        "vectorizer = CountVectorizer()\n",
        "sparse_matrix = vectorizer.fit_transform([emma])\n",
        "\n",
        "# 희소행렬을 CSR 형식으로 변환\n",
        "csr_sparse_matrix = csr_matrix(sparse_matrix.toarray())\n",
        "\n",
        "# CSR 형식의 희소행렬 출력\n",
        "print(\"CSR 형식의 희소행렬:\\n\", csr_sparse_matrix)"
      ],
      "metadata": {
        "id": "OMYoQS1Ew9uX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}